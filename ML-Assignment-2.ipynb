{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boruta in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boruta) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boruta) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boruta) (1.14.3)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "!pip install boruta\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Machine\n",
    "gmb = GradientBoostingClassifier()\n",
    "le_day_of_week = preprocessing.LabelEncoder()\n",
    "le_week_status = preprocessing.LabelEncoder()\n",
    "\n",
    "def secondsDay(data_frame):\n",
    "    hour = data_frame.date.dt.hour\n",
    "    minute = data_frame.date.dt.minute\n",
    "    seconds = data_frame.date.dt.second\n",
    "    return hour * 3600 + minute * 60 + seconds\n",
    "    \n",
    "def weekStatus(data_frame, label_encoder):\n",
    "    week_status_DF = pd.DataFrame(columns=['week_status'])\n",
    "    train_date_DF = pd.DataFrame(columns=['date'])\n",
    "    train_date_DF = data_frame['date']    \n",
    "    for date in train_date_DF.items():\n",
    "        day = date[1].weekday_name\n",
    "        if day == 'Saturday' or day == 'Sunday':\n",
    "            week_status_DF =  week_status_DF.append({'week_status': 'Weekend'}, ignore_index=True)\n",
    "        else:\n",
    "            week_status_DF =  week_status_DF.append({'week_status': 'Weekday'}, ignore_index=True)\n",
    "    \n",
    "    weekstatus_labels = label_encoder.fit_transform(week_status_DF.values.ravel())\n",
    "    return weekstatus_labels\n",
    "\n",
    "def dayOfWeek(data_frame, label_encoder):\n",
    "    day_of_week_label = label_encoder.fit_transform(data_frame.date.dt.weekday_name.values.ravel())\n",
    "    return day_of_week_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:17: FutureWarning: `weekday_name` is deprecated and will be removed in a future version. Use `day_name` instead\n"
     ]
    }
   ],
   "source": [
    "# Pre-process data\n",
    "train_data = pd.read_csv('s3://ml-assignment2-data/UCI-electricity/UCI_data.csv', parse_dates=True)\n",
    "\n",
    "# Generate timeseries eatures for complete dataset\n",
    "train_data['date'] = train_data['date'].astype('datetime64[ns]')\n",
    "\n",
    "# Feature Generation for Timeseries Data\n",
    "# Generate Number of Seconds from Midnight (NSM), \n",
    "nsm_series = secondsDay(train_data)\n",
    "nsm_DF = nsm_series.to_frame()\n",
    "\n",
    "# Week Status of the data, weekend or weekday\n",
    "week_status_DF = pd.DataFrame(data=weekStatus(train_data, le_week_status), columns=['week_status'])\n",
    "\n",
    "# DayOfTheWeek, for each data row\n",
    "day_of_week_DF = pd.DataFrame(data=dayOfWeek(train_data, le_day_of_week), columns=['day_of_week'])\n",
    "\n",
    "train_data['nsm'] = nsm_DF['date']\n",
    "train_data['week_status'] = week_status_DF['week_status']\n",
    "train_data['day_of_week'] = day_of_week_DF['day_of_week']\n",
    "train_data =  train_data.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# SKLEARN to create data partition function, 75% Training, 25% Testing. \n",
    "x_train_DF = train_data.drop(columns=['TARGET_energy'])\n",
    "y_train_DF = pd.DataFrame(train_data['TARGET_energy'], columns=['TARGET_energy'])\n",
    "print(type(y_train_DF))\n",
    "print(type(x_train_DF))\n",
    "x_train_values = x_train_DF.to_numpy().astype('float64')\n",
    "y_train_values = y_train_DF.to_numpy().astype('float64')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train_values, y_train_values, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_scaler = preprocessing.StandardScaler()\n",
    "target_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "x_train_scaled = independent_scaler.fit_transform(X_train)\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "X_train_scaled_DF = pd.DataFrame(x_train_scaled, columns=x_train_DF.columns)\n",
    "Y_train_scaled_DF = pd.DataFrame(y_train_scaled, columns=y_train_DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Performance metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Model & Feature Selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import Models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble  import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20, criterion='mse')\n",
    "\n",
    "feat_selector = RFECV(estimator=rf, step=1, cv=KFold(2))\n",
    "feat_selector.fit(X_train_scaled_DF.to_numpy(), Y_train_scaled_DF.to_numpy().ravel())\n",
    "feat_selector.support_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 3, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMB: 0.307757 (0.016404)\n",
      "LM: 0.158134 (0.014497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFG: 0.536226 (0.047532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "models= []\n",
    "gmb = GradientBoostingRegressor(random_state=4)\n",
    "lm = LinearRegression()\n",
    "rfg = RandomForestRegressor()\n",
    "svr = SVR()\n",
    "\n",
    "models.append(('GMB',gmb))\n",
    "models.append(('LM',lm))\n",
    "models.append(('RFG',rfg))\n",
    "models.append(('SVC',svr))\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "results= []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=4)\n",
    "    cv_results = cross_val_score(model, X_train_scaled_DF.to_numpy(), Y_train_scaled_DF.to_numpy().ravel(), cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
